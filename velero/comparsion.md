Below is a side-by-side look at the three Velero backup styles you just tested, followed by a quick decision guide.

| Dimension                           | **Manifest-only**<br>(metadata / optional CSI snapshots kept on-cluster)                                                                                                | **File-System Backup (FSB)**<br>`--default-volumes-to-fs-backup`                                                                                                                                | **CSI snapshot + Data Mover**<br>`--snapshot-move-data`                                                                                                                                                                          |
| ----------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **What it captures**                | – All Kubernetes objects (YAML).<br>– *Optionally* CSI `VolumeSnapshot` & `VolumeSnapshotContent` objects **only** (no PV data) if `--snapshot-volumes=true` (default). | – Objects **plus** raw file data read from live PVs and streamed to the backup bucket with Kopia/Restic.                                                                                        | – Objects **plus** CSI snapshots **and** a Kopia copy of the *snapshot data* (moved off the storage array).                                                                                                                      |
| **Volume types supported**          | N/A (data not included).                                                                                                                                                | Any RWX/RWO volume that can be mounted in a helper pod (file or block, but block Backup requires the VM/Pod FS inside to be quiesced).                                                          | Any CSI driver that implements *v1 snapshots* and allows the snapshot to be mounted in a temporary PVC (most block providers; file providers still experimental).                                                                |
| **Consistency window**              | None (no data).                                                                                                                                                         | Crash-consistent at best; data is read from a *running* FS → less exact than snapshot; advise fs-freeze hooks for VMs. ([velero.io][1])                                                         | Snapshot time is atomic at the storage layer; data mover copies from that frozen image, giving crash-consistent or storage-consistent backups. ([velero.io][2], [velero.io][3])                                                  |
| **Speed / resource cost**           | Fast & tiny (only tar.gz of manifests).                                                                                                                                 | Slower; node-agent streams every file, heavy network / CPU during copy.                                                                                                                         | Fast snapshot + streaming only once; usually quicker than FSB for large disks but still spends time copying blocks to S3.                                                                                                        |
| **Cluster add-ons needed**          | None beyond core Velero server.                                                                                                                                         | `--use-node-agent` (+ privileged) and Kopia repository; helper pods mount every PVC. ([velero.io][4])                                                                                           | Same node-agent *plus* data-mover controller; extra CRDs (`DataUpload/DataDownload`) and Kopia repo. ([velero.io][3])                                                                                                            |
| **Storage prerequisites**           | None.                                                                                                                                                                   | Volume must be writable & mountable in a pod; RWX is simplest, RWO needs node pinning.                                                                                                          | CSI driver with `VolumeSnapshot` + `Read/Write` snapshot-restore, and enough spare capacity to create temporary clone PVCs.                                                                                                      |
| **Restore destination flexibility** | Can restore to any cluster but **needs original storage class** or manual PV creation for data.                                                                         | Can restore to any cluster & **any** storage class compatible with Pod mount.                                                                                                                   | Can restore to any cluster that has **some** CSI driver (doesn’t have to be the same one) because data is re-hydrated from Kopia, not from the original array.                                                                   |
| **Limitations / gotchas**           | • No application data.<br>• If you enabled snapshots but lose the storage array, the snapshots are useless. ([medium.com][5])                                           | • Still beta quality (as of v1.15). ([velero.io][4]) <br>• Reads live FS → potential inconsistency.<br>• Large volumes = long backup time.<br>• Block-mode PVs need extra fs-freeze or offline. | • Works only with CSI snapshots (in-tree Provisioners unsupported).<br>• Data-mover pods run as root.<br>• Extra storage overhead for temp clone PVC.<br>• Slightly newer code path—watch GitHub for bug fixes. ([velero.io][6]) |
| **Typical use-cases**               | • Stateless apps.<br>• DR when underlying array has its *own* replication<br>• Quick config migration between clusters.                                                 | • NFS, RWX PVCs, or clusters whose storage lacks snapshot support.<br>• Developer clusters where ultimate performance is less critical.                                                         | • Production VMs (KubeVirt, databases) on block storage that **must** survive array loss.<br>• Compliance requiring off-cluster, point-in-time copies.                                                                           |

---

### How to choose in practice

| If you…                                                                                                            | Pick                                   |
| ------------------------------------------------------------------------------------------------------------------ | -------------------------------------- |
| Only need to recreate Kubernetes objects (e.g., rebuild test clusters) and you already replicate storage elsewhere | **Manifest-only**                      |
| Run on storage *without* CSI snapshots or need to back up old NFS volumes                                          | **FSB** (be ready for longer runtimes) |
| Run critical block volumes (RWO) and want cloud-style snapshot durability or cross-cluster restore                 | **CSI snapshot + Data Mover**          |

---

#### Quick sanity check for your three commands

1. **Manifest-only test** – add `--snapshot-volumes=false` as well, otherwise Velero will still create CSI `VolumeSnapshot` objects (just not move data). ([velero.io][7])
2. **FSB** – correct. Make sure the VM’s disks are quiesced (virt-freezer) if consistency matters.
3. **Snapshot + Data Mover** – correct flags; be sure the storage class’s `VolumeSnapshotClass` works end-to-end by trying a manual snapshot/restore first.

Use these pointers as a checklist when deciding which mechanism fits each workload in your cluster mix.

[1]: https://velero.io/docs/v1.15/file-system-backup/?utm_source=chatgpt.com "File System Backup - Velero Docs"
[2]: https://velero.io/docs/main/csi-snapshot-data-movement/?utm_source=chatgpt.com "CSI Snapshot Data Movement - Velero Docs"
[3]: https://velero.io/docs/v1.15/csi-snapshot-data-movement/?utm_source=chatgpt.com "CSI Snapshot Data Movement - Velero Docs"
[4]: https://velero.io/docs/v1.10/file-system-backup/?utm_source=chatgpt.com "File System Backup - Velero Docs"
[5]: https://medium.com/linux-shots/backup-kubernetes-using-velero-and-csi-volume-snapshot-4155d4e32e5d?utm_source=chatgpt.com "Backup Kubernetes using Velero and CSI volume snapshot - Medium"
[6]: https://velero.io/docs/v1.15/data-movement-pod-resource-configuration/?utm_source=chatgpt.com "Data Movement Pod Resource Configuration - Velero Docs"
[7]: https://velero.io/docs/v1.14/how-velero-works/?utm_source=chatgpt.com "How Velero Works"
